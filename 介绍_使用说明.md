# Gemini CLI MCP/OpenAI 桥接服务器 - 项目介绍与使用说明

## 项目概述

`@intelligentinternet/gemini-cli-mcp-openai-bridge` 是一个基于 Google 开源 Gemini CLI 构建的多功能桥接服务器，提供两个核心功能：

1. **MCP (Model Context Protocol) 工具包服务器** - 将 Gemini CLI 的所有内置工具通过标准化的 MCP 协议暴露
2. **OpenAI 兼容 API 桥接器** - 提供完全兼容 OpenAI Chat Completions API 的端点

## 项目架构 (ASTL - Architecture, Structure, Technology, Logic)

### Architecture (架构)

```
┌─────────────────────────────────────────────────────────────┐
│                    客户端应用层                              │
│  ┌─────────────────┐    ┌─────────────────────────────────┐ │
│  │   MCP 客户端    │    │    OpenAI API 客户端           │ │
│  │  (Claude, etc.) │    │  (Open WebUI, ChatGPT, etc.)   │ │
│  └─────────────────┘    └─────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────┘
                           │
                           ▼
┌─────────────────────────────────────────────────────────────┐
│                 Bridge Server (Express.js)                 │
│  ┌─────────────────┐    ┌─────────────────────────────────┐ │
│  │   MCP 端点      │    │    OpenAI API 端点             │ │
│  │   /mcp          │    │    /v1/chat/completions        │ │
│  │                 │    │    /v1/models                  │ │
│  └─────────────────┘    └─────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────┘
                           │
                           ▼
┌─────────────────────────────────────────────────────────────┐
│                  Gemini CLI Core                           │
│  ┌─────────────────┐    ┌─────────────────────────────────┐ │
│  │   工具注册表    │    │    Gemini API 客户端           │ │
│  │  Tool Registry  │    │    (认证 & 模型调用)            │ │
│  └─────────────────┘    └─────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────┘
                           │
                           ▼
┌─────────────────────────────────────────────────────────────┐
│                    Google Gemini API                       │
└─────────────────────────────────────────────────────────────┘
```

### Structure (项目结构)

```
gemini-cli-mcp-openai-bridge/
├── 📁 bridge-server/                    # 核心桥接服务器代码
│   ├── 📁 src/
│   │   ├── 📁 bridge/                   # 桥接逻辑
│   │   │   ├── bridge.ts               # MCP 桥接核心类
│   │   │   ├── openai.ts               # OpenAI API 兼容层
│   │   │   └── stream-transformer.ts   # 流式响应转换器
│   │   ├── 📁 config/                   # 配置管理
│   │   │   ├── config.ts               # 主配置加载器
│   │   │   ├── settings.ts             # 设置文件解析
│   │   │   ├── extension.ts            # 扩展配置
│   │   │   └── sandboxConfig.ts        # 沙箱配置
│   │   ├── 📁 utils/                    # 工具函数
│   │   │   ├── logger.ts               # 日志系统
│   │   │   ├── error-mapper.ts         # 错误映射
│   │   │   ├── package.ts              # 包信息
│   │   │   └── version.ts              # 版本管理
│   │   ├── index.ts                    # 服务器入口点
│   │   ├── gemini-client.ts            # Gemini 客户端封装
│   │   ├── mcp-test-client.ts          # MCP 测试客户端
│   │   └── types.ts                    # TypeScript 类型定义
│   ├── package.json                    # 依赖配置
│   └── tsconfig.json                   # TypeScript 配置
├── 📁 gemini-cli/                       # Google Gemini CLI 子模块
├── 📁 .trae/                           # Trae AI IDE 配置
├── 📁 .vscode/                         # VS Code 配置
├── _example.settings.json              # 示例配置文件
├── Dockerfile                          # Docker 容器配置
├── package.json                        # 根项目配置
└── README.zh.md                        # 中文说明文档
```

### Technology (技术栈)

#### 核心技术
- **Node.js** (≥18.0.0) - 运行时环境
- **TypeScript** - 主要开发语言
- **Express.js** - Web 服务器框架
- **@google/gemini-cli-core** - Google Gemini CLI 核心库
- **@modelcontextprotocol/sdk** - MCP 协议实现

#### 关键依赖
- **openai** - OpenAI API 类型定义和客户端
- **zod** - 运行时类型验证
- **undici** - 高性能 HTTP 客户端
- **dotenv** - 环境变量管理
- **express** - HTTP 服务器
- **command-exists** - 命令存在性检查

#### 开发工具
- **vitest** - 测试框架
- **eslint** - 代码检查
- **prettier** - 代码格式化
- **rimraf** - 跨平台文件删除
- **shx** - 跨平台 shell 命令

### Logic (核心逻辑)

#### 1. 安全策略系统

项目实现了四层安全模式：

```typescript
type SecurityMode = 'read-only' | 'edit' | 'configured' | 'yolo';

// read-only: 仅允许只读工具 (默认)
// edit: 允许文件编辑，禁止 shell 命令
// configured: 基于配置文件的精细控制
// yolo: 允许所有操作 (高风险)
```

#### 2. 工具注册与过滤

```typescript
// 工具过滤逻辑
switch (securityPolicy.mode) {
  case 'read-only':
    // 仅注册只读工具
    tools = allTools.filter(tool => isReadOnlyTool(tool.name));
    break;
  case 'edit':
    // 排除 shell 命令工具
    tools = allTools.filter(tool => tool.name !== 'run_shell_command');
    break;
  case 'configured':
    // 基于白名单过滤
    tools = allTools.filter(tool => allowedTools.includes(tool.name));
    break;
  case 'yolo':
    // 允许所有工具
    tools = allTools;
    break;
}
```

#### 3. MCP 协议桥接

```typescript
// MCP 服务器创建和工具注册
const server = new McpServer({
  name: 'gemini-cli-bridge-server',
  version: cliVersion,
}, {
  capabilities: {
    logging: {},
    geminiCliSecurityPolicy: securityPolicy,
  },
});

// 注册 Gemini CLI 工具为 MCP 工具
for (const tool of availableTools) {
  server.setRequestHandler(CallToolRequestSchema, async (request) => {
    const result = await tool.execute(request.params.arguments);
    return { content: [{ type: 'text', text: result.text }] };
  });
}
```

#### 4. OpenAI API 兼容层

```typescript
// OpenAI 消息格式转换为 Gemini 格式
function convertOpenAIToGemini(messages: OpenAIMessage[]): Content[] {
  return messages.map(msg => ({
    role: msg.role === 'assistant' ? 'model' : 'user',
    parts: [{ text: msg.content }]
  }));
}

// Gemini 响应转换为 OpenAI 格式
function convertGeminiToOpenAI(response: GenerateContentResponse): OpenAIChatCompletion {
  return {
    id: randomUUID(),
    object: 'chat.completion',
    created: Math.floor(Date.now() / 1000),
    model: 'gemini-2.5-flash',
    choices: [{
      index: 0,
      message: {
        role: 'assistant',
        content: response.text()
      },
      finish_reason: 'stop'
    }]
  };
}
```

## 详细使用说明

### 1. 环境准备

#### 系统要求
- **Node.js** ≥ 18.0.0
- **npm** 或 **yarn**
- **Git** (用于子模块)
- **macOS/Linux/Windows** (推荐 macOS/Linux)

#### 认证配置

项目使用与 Gemini CLI 相同的认证机制：

```bash
# 方式1: 使用 API Key
export GEMINI_API_KEY="your-api-key-here"

# 方式2: 使用 Google Cloud 认证
export GOOGLE_APPLICATION_CREDENTIALS="/path/to/service-account.json"

# 方式3: 使用 gcloud CLI (推荐)
gcloud auth application-default login
```

### 2. 安装与启动

#### 全局安装 (推荐)

```bash
# 安装
npm install -g @intelligentinternet/gemini-cli-bridge

# 启动服务器
gemini-cli-bridge

# 自定义配置启动
gemini-cli-bridge --host=0.0.0.0 --port=9000 --debug
```

#### 从源码构建

```bash
# 克隆项目
git clone https://github.com/Intelligent-Internet/gemini-cli-common-bridge.git
cd gemini-cli-common-bridge

# 安装依赖 (会自动初始化子模块)
npm install

# 构建项目
npm run build

# 启动服务器
npm run start
```

#### Docker 部署

```bash
# 构建镜像
docker build -t gemini-cli-bridge .

# 运行容器
docker run -p 8765:8765 \
  -e GEMINI_API_KEY="your-api-key" \
  gemini-cli-bridge
```

### 3. 命令行参数详解

| 参数 | 别名 | 环境变量 | 默认值 | 说明 |
|------|------|----------|--------|---------|
| `--host` | `-h` | - | `127.0.0.1` | 服务器监听地址 |
| `--port` | `-p` | `GEMINI_MCP_PORT` | `8765` | 服务器端口 |
| `--target-dir` | `-d` | - | 当前目录 | 文件操作根目录 |
| `--debug` | - | - | `false` | 启用调试日志 |
| `--use-internal-prompt` | - | - | `false` | 加载内部 GEMINI.md 提示 |
| `--tools-model` | - | `GEMINI_TOOLS_DEFAULT_MODEL` | `gemini-2.5-flash` | 工具执行模型 |
| `--mode` | - | - | `read-only` | 安全模式 |
| `--allow-mcp-proxy` | - | - | `false` | 允许 MCP 代理工具 |
| `--resolve-redirects` | - | - | `false` | 解析重定向 URL |
| `--i-know-what-i-am-doing` | - | - | `false` | 跳过安全确认 |

### 4. 安全配置详解

#### 安全模式说明

1. **read-only** (默认，最安全)
   - ✅ 允许：`read_file`, `list_directory`, `glob`, `google_web_search`
   - ❌ 禁止：所有写入操作、shell 命令、MCP 代理

2. **edit** (平衡模式)
   - ✅ 允许：所有文件读写操作
   - ❌ 禁止：`run_shell_command`、MCP 代理

3. **configured** (自定义模式)
   - 完全基于 `settings.json` 配置
   - 需要明确列出允许的工具

4. **yolo** (最危险)
   - ✅ 允许：所有本地工具
   - ⚠️ 风险：可执行任意系统命令

#### 配置文件示例

创建 `.gemini/settings.json`：

```json
{
  "securityPolicy": {
    "mode": "configured",
    "allowedTools": [
      "read_file",
      "write_file",
      "list_directory",
      "google_web_search",
      "run_shell_command"
    ],
    "shellCommandPolicy": {
      "allow": [
        "ls", "git status", "npm install", "npm test"
      ],
      "deny": [
        "rm", "sudo", "docker", "chmod"
      ]
    }
  },
  "mcpServers": {
    "github": {
      "command": "docker",
      "args": ["run", "-i", "--rm", "-e", "GITHUB_PERSONAL_ACCESS_TOKEN=${GITHUB_PAT}", "ghcr.io/github/github-mcp-server"],
      "trust": true
    }
  }
}
```

### 5. API 使用示例

#### MCP 客户端连接

```python
# Python MCP 客户端示例
import asyncio
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

async def main():
    server_params = StdioServerParameters(
        command="curl",
        args=["-X", "POST", "http://localhost:8765/mcp"]
    )
    
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            # 初始化连接
            await session.initialize()
            
            # 列出可用工具
            tools = await session.list_tools()
            print(f"Available tools: {[tool.name for tool in tools.tools]}")
            
            # 调用工具
            result = await session.call_tool(
                "read_file",
                {"file_path": "/path/to/file.txt"}
            )
            print(f"File content: {result.content}")

asyncio.run(main())
```

#### OpenAI API 兼容调用

```python
# 使用 OpenAI Python 客户端
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:8765/v1",
    api_key="dummy-key"  # 不需要真实 API key
)

# 聊天补全
response = client.chat.completions.create(
    model="gemini-2.5-flash",
    messages=[
        {"role": "system", "content": "你是一个有用的助手。"},
        {"role": "user", "content": "请帮我读取当前目录下的 README.md 文件"}
    ],
    tools=[
        {
            "type": "function",
            "function": {
                "name": "read_file",
                "description": "读取文件内容",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "file_path": {
                            "type": "string",
                            "description": "文件路径"
                        }
                    },
                    "required": ["file_path"]
                }
            }
        }
    ]
)

print(response.choices[0].message.content)
```

```javascript
// JavaScript/Node.js 示例
const OpenAI = require('openai');

const client = new OpenAI({
  baseURL: 'http://localhost:8765/v1',
  apiKey: 'dummy-key'
});

async function chatWithTools() {
  const response = await client.chat.completions.create({
    model: 'gemini-2.5-flash',
    messages: [
      { role: 'user', content: '请搜索最新的 AI 新闻' }
    ],
    tools: [
      {
        type: 'function',
        function: {
          name: 'google_web_search',
          description: '搜索网络信息',
          parameters: {
            type: 'object',
            properties: {
              query: { type: 'string', description: '搜索查询' }
            },
            required: ['query']
          }
        }
      }
    ]
  });
  
  console.log(response.choices[0].message.content);
}

chatWithTools();
```

#### cURL 示例

```bash
# 获取可用模型
curl -X GET http://localhost:8765/v1/models

# 聊天补全
curl -X POST http://localhost:8765/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gemini-2.5-flash",
    "messages": [
      {"role": "user", "content": "Hello, world!"}
    ]
  }'

# 流式响应
curl -X POST http://localhost:8765/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gemini-2.5-flash",
    "messages": [
      {"role": "user", "content": "写一首诗"}
    ],
    "stream": true
  }'
```

### 6. 集成示例

#### 与 Open WebUI 集成

1. 在 Open WebUI 中添加新的 OpenAI 兼容模型：
   - Base URL: `http://localhost:8765/v1`
   - API Key: `dummy-key`
   - Model: `gemini-2.5-flash`

2. 启用工具调用功能，即可使用 Gemini CLI 的所有工具

#### 与 Claude Desktop 集成

在 Claude Desktop 的 MCP 配置中添加：

```json
{
  "mcpServers": {
    "gemini-cli-bridge": {
      "command": "curl",
      "args": ["-X", "POST", "http://localhost:8765/mcp"]
    }
  }
}
```

### 7. 故障排除

#### 常见问题

1. **认证失败**
   ```bash
   # 检查认证状态
   gcloud auth application-default print-access-token
   
   # 重新认证
   gcloud auth application-default login
   ```

2. **端口被占用**
   ```bash
   # 查看端口占用
   lsof -i :8765
   
   # 使用其他端口
   gemini-cli-bridge --port=9000
   ```

3. **子模块未初始化**
   ```bash
   # 手动初始化子模块
   git submodule update --init --recursive
   ```

4. **工具权限被拒绝**
   - 检查安全模式设置
   - 确认工具在 `allowedTools` 列表中
   - 查看服务器日志了解具体原因

#### 调试技巧

```bash
# 启用详细日志
gemini-cli-bridge --debug

# 检查配置
gemini-cli-bridge --debug --mode=configured

# 测试特定工具
curl -X POST http://localhost:8765/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "jsonrpc": "2.0",
    "id": 1,
    "method": "tools/list"
  }'
```

### 8. 性能优化

#### 推荐配置

```bash
# 生产环境启动
gemini-cli-bridge \
  --host=0.0.0.0 \
  --port=8765 \
  --mode=configured \
  --tools-model=gemini-2.5-flash \
  --target-dir=/app/workspace
```

#### 资源监控

```bash
# 监控服务器状态
top -p $(pgrep -f gemini-cli-bridge)

# 检查内存使用
ps aux | grep gemini-cli-bridge
```

## 总结

本项目成功地将 Google Gemini CLI 的强大功能通过标准化的 MCP 和 OpenAI API 接口暴露出来，为 AI 应用开发提供了一个安全、灵活、易于集成的桥接解决方案。通过分层的安全策略和丰富的配置选项，既保证了系统的安全性，又提供了足够的灵活性来满足不同场景的需求。